# --- WORKSPACE SETUP --- #

# Probabilistic programming
using Turing, TuringBenchmarking, ReverseDiff, ParetoSmooth
# Model speed optimization
using LazyArrays
# Statistics
using StatsFuns
import LinearAlgebra: I
# Working with tabular data
using Chain, DataFrames
# Plotting
using StatsPlots
# Saving results and logging
using Serialization, CSV, Dates, Markdown
# Random seeds
using Random

# Path
const ROOT = dirname(Base.active_project())

# Load custom modules
include("$ROOT/scripts/modelzoo.jl")
include("$ROOT/src/count.jl")
include("$ROOT/src/utilities.jl")

# Make custom modules available
using .CountVariables
using .CountModels
using .CustomUtilityFuns

# Set seed
Random.seed!(42)

# Benchmark model?
benchmark = false

# Run the sampler?
run = isempty(ARGS) ? false : ARGS[1] == "true"

# Prior settings can be set from command line
# Ïƒâ‚š, Î¸â‚š = 1, 2

# if !run
#     @info "Loading chain, no model fit."
# elseif isempty(ARGS) || ARGS[2] == "default"
#     @info "Fitting model with default priors: Ïƒâ‚š=$Ïƒâ‚š, Î¸â‚š=$Î¸â‚š."
# elseif all(ARGS[2] .!= ["narrow", "wide"])
#     throw("Unknown prior setting: '$(ARGS[2])'. Pass nothing or one of 'default', 'narrow', 'wide'.")
# else
#     Ïƒâ‚š, Î¸â‚š = ARGS[2] == "wide" ? [Ïƒâ‚š, Î¸â‚š] .* 3 : [Ïƒâ‚š, Î¸â‚š] .* 1 / 3
#     @info "Fitting model with $(ARGS[2]) priors: Ïƒâ‚š=$(round(Ïƒâ‚š, digits=2)), Î¸â‚š=$(round(Î¸â‚š, digits=2))."
# end

if ARGS[2] == "S" # simplest model
    # model = m1p
    # inputs = (; num_region, num_species)
elseif isempty(ARGS) || ARGS[2] == "M" # most complex model
    model = mMc
    # What does the auto named tuple notation (; ...) do with splatted vectors?
    inputs = (num_region_known, num_species_known, num_nesting_known, PC_known, num_species_within_nesting_known, unique_nesting_known, unique_species_within_nesting_known, count_species_by_nesting...,)
elseif isempty(ARGS) || ARGS[2] == "L" # large model
    # model = mLp
    # What does the auto named tuple notation (; ...) do with splatted vectors?
    # inputs = (num_region, num_species, num_nesting, PC, num_species_within_nesting, unique_nesting, unique_species_within_nesting, count_species_by_nesting...,)
elseif ARGS[2] == "XL"
    # model = mXLp
    # What does the auto named tuple notation (; ...) do with splatted vectors?
    # inputs = (num_atoll, num_region, num_species, num_nesting, PC, num_species_within_nesting, unique_nesting, unique_species_within_nesting, count_species_by_nesting...,)
end

PRIORSUFFIX = isempty(ARGS) ? "default" : ARGS[2]

# If not loading a chain, save results to path below
chainpath = "count.jls"

standardise(x) = (x .- mean(x)) ./ std(x)

zlogn = standardise(log.(nbirds))

# --- PRIOR PREDICTIVE CHECKS --- #

chain_prior = sample(model(inputs..., zlogn), Prior(), 1000);

Î¸_prior = let
    peaceful_generated_quantities(model(inputs..., zlogn), chain_prior);
    k = keys(Î¸_prior[1])
    vec(getsamples(Î¸_prior, k...))
end

let 
    priorsamples = reduce(vcat, simulate(Î¸_prior, inputs...))
    histogram(zlogn, normalize=true, c=1)
    density!(priorsamples, normalize=true, c=:white, lw=3)
    density!(priorsamples, normalize=true, c=2, fillrange=0, lw=1.5, fillalpha=0.2, legend=false)
end 
# not sure if necessary to show both observed and prior for prior predictive check
# I guess it's not bad on a second thought though â€“ we don't want probability mass in useless places

# Benchmark different backends to find out which is fastest
let adbackends = [:forwarddiff, :reversediff, :reversediff_compiled]
    benchmark && benchmark_model(model; check=true, adbackends=adbackends)
end

# Sample from model unless a saved chain should be used
if !run
    chain = deserialize("$ROOT/results/chains/$chainpath")
else
    # Set AD backend to :reversediff and compile with setrdcache(true)
    Turing.setadbackend(:reversediff)
    Turing.setrdcache(true)

    # Configure sampling
    sampler = NUTS(1000, 0.95; max_depth=10)
    nsamples = 2000
    nchains = 4
    ndiscard = 200

    @info """Sampler: $(string(sampler))
    Samples: $(nsamples)
    Chains: $(nchains)
    Discard: $(ndiscard)
    """

    @info "ğŸš€ Starting sampling: $(Dates.now())"
    chain = sample(model(inputs..., zlogn), sampler, MCMCThreads(), nsamples, nchains; discard_initial=ndiscard)

    serialize("$ROOT/results/chains/$chainpath", chain)
    @info "ğŸ’¾ Chain saved to '$ROOT/results/chains/$chainpath'."
end;

# --- POSTERIOR PREDICTIVE CHECK --- #

Î¸_post = let
    gqs = peaceful_generated_quantities(model(inputs..., zlogn), chain)
    k = keys(Î¸_post[1])
    vec(getsamples(gqs, k...))
end

let 
    postsamples = reduce(hcat, simulate(Î¸_post, inputs...))

    plots = map(enumerate(unique(num_species_known))) do (index, species)
        pred_x = vec(mean(postsamples[num_species_known.==species, :], dims=2))
        obs_x = zlogn[num_species_known.==species]
        scatter(obs_x, markersize=2.5, msc=1, label="O")
        scatter!(pred_x, markersize=2.5, msc=2, yticks=:none, label="P")
        #title!(unique(str_species)[index], titlefontsize=8)
    end

    plot(plots..., titlefontsize=9, size=(800,1200), layout=(8,5))
end

# Goal here is scatter plots that also show uncertainty in estimates â€“ maybe even violins? Too busy...

predictions = 
    let thresholds = 0.75:0.05:0.85 
        @chain thresholds begin
            map(_) do threshold
                pass = ppres .> threshold
                unknown_inputs = (num_region_unknown[pass], num_species_unknown[pass], num_nesting_known, PC_unknown[pass, :], num_species_within_nesting_unknown[pass], unique_nesting_known, unique_species_within_nesting_known, count_species_by_nesting...,)
                samples = reduce(hcat, simulate(Î¸_post, unknown_inputs...))
            end
        Dict(Pair.(thresholds, _))
    end
end


countpreds_unknown = @chain begin
    predictcount(
        Î±,
        Î²,
        Ïƒ2,
        num_species_within_nesting_unknown[threshold],
        num_species_unknown[threshold],
        num_region_unknown[threshold],
        PC_unknown[threshold, :],
    )
    reduce(hcat, _)
    Matrix{Float64}(_)
end

between(x, lower, upper) = lower â‰¤ x && x â‰¤ upper

countpreds_oos = @chain begin
    predictcount(
        Î±,
        Î²,
        Ïƒ2,
        num_species_within_nesting_oos,
        num_species_oos,
        num_region_oos,
        PC_oos,
    )
    reduce(hcat, _)
    Matrix{Float64}(_)
    mean(_, dims=2)
    exp.(_)
    #[between(_[i], oos_lims[i][1], oos_lims[i][2]) for i in eachindex(_)]
    [_ oos_lims [between(_[i], oos_lims[i][1], oos_lims[i][2]) for i in eachindex(_)] sort(unique(str_species_known))[num_species_oos]]
end



countpreds_known = @chain begin
    predictcount(
        Î±,
        Î²,
        Ïƒ2,
        num_species_within_nesting_known,
        num_species_known,
        num_region_known,
        PC_known,
    )
    reduce(hcat, _)
    Matrix{Float64}(_)
end

avg_preds_unknown = vec(mean(countpreds_unknown, dims=2))
avg_preds_known = vec(mean(countpreds_known, dims=2))

df_countpreds = DataFrame(
    [
        num_atoll_unknown[threshold],
        num_region_unknown[threshold],
        num_species_unknown[threshold],
        avg_preds_unknown
    ],
    [:atoll, :region, :species, :nbirds]
)

CSV.write("$ROOT/results/data/countpreds_$PRIORSUFFIX.csv", df_countpreds)
@info "Successfully saved predictions to `$ROOT/results/data/countpreds_$PRIORSUFFIX.csv`."

# Overall posterior predictive checks
hist_overall_postpc = histogram(log.(nbirds), normalize=true, lw=0.5, lc=:white, label="Observed")
histogram!(vec(countpreds_known), normalize=true, c=:white, lw=3, label=false)
histogram!(vec(countpreds_known), normalize=true, c=2, lw=1.5, label="Predicted")
title!("Posterior predictive check"); xlabel!("log(Count)"); ylabel!("Density")

# Gather prior and posterior predictive checks into single plot
grid_pppc = plot(hist_overall_priorpc, hist_overall_postpc, size=(800, 500))
xlims!(-30, 30)
display(grid_pppc)
savefig("$ROOT/results/svg/validation_count_pppc.svg")

# Species-specific checks
hist_species_postpc = map(enumerate(unique(num_species_known))) do (index, species)
    pred_x = avg_preds_known[num_species_known.==species]
    obs_x = log.(nbirds)[num_species_known.==species]
    scatter(eachindex(pred_x), obs_x, markersize=2.5, msc=1, label="O")
    scatter!(eachindex(pred_x), pred_x, markersize=2.5, msc=2, label="P", xformatter=_->"")
    title!(unique(str_species_known)[index])
end

grid_species_ppc = plot(hist_species_postpc..., layout=(8,5), size=(1000, 1400), titlefontsize=9)
savefig("$ROOT/results/svg/validation_count_postpc_species.svg")


# --- LOO CV --- #

# It seems that specifying the model as MvNormal breaks psis_loo ("1 data point")
# Respecify the likelihood as vectorized Normals
# y .~ Normal.(Î¼, Ïƒ)
# Can still use the fit chain though because formulas are identical.

@model function loospecial(
    r, s, n, PC, y,
    idx_sn, u_n, u_sn, Nv, Ng, Nb;
    Nr=lu(r), Ns=lu(s), Nn=lu(n), NPC=size(PC, 2), idx_sr=idx(s, r)
)

    # Priors for species Ã— region
    Î¼_sxr ~ filldist(Normal(0, Ïƒâ‚š), Ns)
    Ï„_sxr ~ filldist(InverseGamma(3, Î¸â‚š), Ns)
    z_sxr ~ filldist(Normal(), Ns, Nr)
    Î±_sxr = Î¼_sxr .+ Ï„_sxr .* z_sxr

    # Priors for nesting types Ã— PCs
    Î¼_pxn ~ filldist(Normal(0, Ïƒâ‚š), Nn, NPC)
    Ï„_pxn ~ filldist(InverseGamma(3, Î¸â‚š), Nn, NPC)
    z_pxb ~ filldist(Normal(), Nb, NPC)
    z_pxg ~ filldist(Normal(), Ng, NPC)
    z_pxv ~ filldist(Normal(), Nv, NPC)
    z_pxn = ApplyArray(vcat, z_pxb, z_pxg, z_pxv)
    Î²_pxn = Î¼_pxn[u_n, :] .+ Ï„_pxn[u_n, :] .* z_pxn[u_sn, :]

    # Prior for random error
    Ïƒ2 ~ InverseGamma(3, Î¸â‚š)

    # Likelihood
    Î¼ = vec(Î±_sxr[idx_sr] + sum(Î²_pxn[idx_sn, :] .* PC, dims=2))
    y .~ Normal.(Î¼, Ïƒ2)

    # Generated quantities
    return (; y, Î±_sxr, Î²_pxn)
end;

loomodel = loospecial(
    num_region_known,
    num_species_known,
    num_nesting_known,
    PC_known,
    log.(nbirds),
    num_species_within_nesting_known,
    unique_nesting_known,
    unique_species_within_nesting_known,
    count_species_by_nesting...,
);

cv_res = psis_loo(loomodel, chain)

# Variance priors: Exponential(1).^2  #
# ----------------------------------- #
# Warning: Some Pareto k values are extremely high (>1). PSIS will not produce consistent estimates.
# Results of PSIS-LOO-CV with 8000 Monte Carlo samples and 861 data points. Total Monte Carlo SE of 0.45.
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚           â”‚    total â”‚ se_total â”‚  mean â”‚ se_mean â”‚
# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
# â”‚   cv_elpd â”‚ -1927.46 â”‚    26.03 â”‚ -2.24 â”‚    0.03 â”‚
# â”‚ naive_lpd â”‚ -1787.33 â”‚    18.71 â”‚ -2.08 â”‚    0.02 â”‚
# â”‚     p_eff â”‚   140.13 â”‚     8.97 â”‚  0.16 â”‚    0.01 â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# Variance priors: InverseGamma(3, 0.1)  #
# -------------------------------------- #
# No warning
# Results of PSIS-LOO-CV with 8000 Monte Carlo samples and 861 data points. Total Monte Carlo SE of 0.11.
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚           â”‚    total â”‚ se_total â”‚  mean â”‚ se_mean â”‚
# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
# â”‚   cv_elpd â”‚ -2221.51 â”‚     4.99 â”‚ -2.58 â”‚    0.01 â”‚
# â”‚ naive_lpd â”‚ -2215.20 â”‚     4.74 â”‚ -2.57 â”‚    0.01 â”‚
# â”‚     p_eff â”‚     6.31 â”‚     0.33 â”‚  0.01 â”‚    0.00 â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
